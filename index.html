<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Shrinivas Ramasubramanian</title>

    <meta name="author" content="Shrinivas Ramasubramanian">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Shrinivas Ramasubramanian
                </p>
                <p>I am an incoming Grad Student at Carnegie Mellon University. Currently I'm a research engineer at <a href="https://www.fujitsu.com/in/about/local/corporate/subsidiaries/fri-research-vision.html">Fujitsu Research</a> in Bangalore, where I work in collaboration with Fujitsu Research Japan and  <a href="https://val.cds.iisc.ac.in/">Vision and AI lab, IISc</a> optimizing non-decomposable objectives and person re-identification. I also collaborate with Fujitsu Research India where I primarily focus on the use of graph neural networks for large scale data. I did my undergrad at <a href="https://www.iitb.ac.in/">IIT Bombay</a>, in Electrical Engineering. 
                </p>
                <p style="text-align:center">
                  <a href="mailto:shrinivas.ramasubramanian@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Resume_Split.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=igm1_28AAAAJ">Scholar</a> &nbsp;/&nbsp;
				        <a href="https://github.com/stablegradients">Github</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/shrinivas-ramasubramanian-2953721b9/">Linkedin</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Shrinivas.JPG" target="_blank"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Shrinivas.JPG" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My primary area of focus is optimizing non-decomposable objectives, i.e objectives inxepressible as an average of a function of label-prediction pairs. They are often usefull in fairness based objectives and constrained optimization problem. My secondary areas of research are classification on class-imbalanced data and representation learning.
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
                <img src="images/cam_image.png" >
                Your browser does not support the video tag.
                </video></div>
                <img src="images/cam_image.png"  width="160">
                </div>
                <script type="text/javascript">
                  function difsurvey_start() {
                    document.getElementById('difsurvey_image').style.opacity = "1";
                  }

                  function difsurvey_stop() {
                    document.getElementById('difsurvey_image').style.opacity = "0";
                  }
                  difsurvey_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openreview.net/forum?id=rxVBKhyfSo">
                  <span class="papertitle">Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Metrics
            </span>
                </a>
                <br>
              <strong>Shrinivas Ramasubramanian*</strong>,
              <a href="https://rangwani-harsh.github.io/about/">Harsh Rangwani*</a>,
              <a href="https://dblp.dagstuhl.de/pid/155/7291.html">Sho Takemori*</a>,
              <a href="https://scholar.google.com/citations?user=fIzwATkAAAAJ&hl=en">Kunal Samanta</a>,
              <a href="https://scholar.google.com/citations?user=8NWN3xAAAAAJ&hl=ja">Umeda Yuhei</a>,
              <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a>,
              <br>
              <em>ICLR<em>, 2024 <strong>( accept spotlight !!) </strong>
                <br>
                <p></p>
                <p>
                  Internet usage growth generates massive data, prompting adoption of supervised/semi-supervised machine learning. Pre-deployment model evaluation, considering worst-case recall and fairness, is crucial. Current techniques lack on non-decomposable objectives; theoretical methods demand building new models for each. Introducing SelMixâ€”a selective mixup-based, cost-effective fine-tuning for pre-trained models. SelMix optimizes specific objectives through feature mixup between class samples. Outperforming existing methods on imbalanced classification benchmarks, SelMix significantly enhances practical, non-decomposable objectives.
                </p>
              </td>
            </tr> 

            <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
                <div>
                <a target="_blank" href="images/Selmix.png">
                <img src="images/Selmix.png" >
                </a>
                </div>
                Your browser does not support the video tag.
                </video></div>
                <div><a target="_blank" href="images/Selmix.png">
                <img src="images/Selmix.png"  width="160"></a></div>
                </div>
                <script type="text/javascript">
                  function difsurvey_start() {
                    document.getElementById('difsurvey_image').style.opacity = "1";
                  }
            
                  function difsurvey_stop() {
                    document.getElementById('difsurvey_image').style.opacity = "0";
                  }
                  difsurvey_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://differentiable.xyz/papers/paper_28.pdf">
                  <span class="papertitle">SelMix: Selective Mixup Fine Tuning for Optimizing Non-Decomposable Metrics
            </span>
                </a>
                <br>
              <strong>Shrinivas Ramasubramanian*</strong>,
              <a href="https://rangwani-harsh.github.io/about/">Harsh Rangwani*</a>,
              <a href="https://dblp.dagstuhl.de/pid/155/7291.html">Sho Takemori*</a>,
              <a href="https://scholar.google.com/citations?user=fIzwATkAAAAJ&hl=en">Kunal Samanta</a>,
              <a href="https://scholar.google.com/citations?user=8NWN3xAAAAAJ&hl=ja">Umeda Yuhei</a>,
              <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a>,
              <br>
              <em>ICML workshop, Differentiable Almost Everything <em>, 2023
                <br>
                <p></p>
                <p>
                  SelMix is a fine-tuning technique designed to enhance machine learning models' performance on imbalanced data with non-decomposable objectives, such as fairness criteria. It optimizes feature mixup between specific classes to address class imbalance and outperforms existing methods on benchmark datasets.
                </p>
              </td>
            </tr>                

            <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
                <img src="images/CSST.png" >
                Your browser does not support the video tag.
                </video></div>
                <img src="images/CSST.png"  width="160">
                </div>
                <script type="text/javascript">
                  function difsurvey_start() {
                    document.getElementById('difsurvey_image').style.opacity = "1";
                  }

                  function difsurvey_stop() {
                    document.getElementById('difsurvey_image').style.opacity = "0";
                  }
                  difsurvey_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2304.14738">
                  <span class="papertitle">Cost-Sensitive Self-Training for Optimizing Non-Decomposable Metrics
            </span>
                </a>
                <br>
              <a href="https://rangwani-harsh.github.io/about/">Harsh Rangwani*</a>,
              <strong>Shrinivas Ramasubramanian*</strong>,
              <a href="https://dblp.dagstuhl.de/pid/155/7291.html">Sho Takemori*</a>,
              Kato Takashi,
              <a href="https://scholar.google.com/citations?user=8NWN3xAAAAAJ&hl=ja">Umeda Yuhei</a>,
              <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a>,
              <br>
              <em>NeurIPS<em>, 2022
                <br>
                <p></p>
                <p>
                  This work introduces the Cost-Sensitive Self-Training (CSST) framework, which extends self-training-based methods to optimize non-decomposable metrics in practical machine learning systems. The CSST framework proves effective in improving non-decomposable metric optimization using unlabeled data, leading to better results in various vision and NLP tasks compared to the state-of-the-art methods.
                </p>
              </td>
            </tr> 
            
            <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
                <img src="images/cam_image.png" >
                Your browser does not support the video tag.
                </video></div>
                <img src="images/cam_image.png"  width="160">
                </div>
                <script type="text/javascript">
                  function difsurvey_start() {
                    document.getElementById('difsurvey_image').style.opacity = "1";
                  }

                  function difsurvey_stop() {
                    document.getElementById('difsurvey_image').style.opacity = "0";
                  }
                  difsurvey_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">In Submission
            </span>
                
                <br>
              <a href="https://pangzhan27.github.io/">Pang Zhanzong</a>,
              <a href="https://scholar.google.com/citations?user=-juoweoAAAAJ&hl=en">Fadime Sener</a>,
              <strong>Shrinivas Ramasubramanian</strong>,
              <a href="https://www.comp.nus.edu.sg/~ayao/">Angela Yao</a>
              <br>
              <em>ECCV<em>, 2024
                <br>
                <p></p>
                <p>
                  Temporal action segmentation assigns labels to each frame in untrimmed videos, often facing a long-tailed action distribution due to varying action frequencies and durations. However, current methods overlook this issue and struggle with recognizing rare actions. Existing long-tail methods, which make class-independent assumptions, also fall short in this context. To address these challenges, we propose a novel framework called Group-wise Temporal Logit Adjustment (G-TLA). G-TLA leverages activity information and action order to improve tail action recognition. Our approach shows significant improvements on five temporal segmentation benchmarks.
                </p>
              </td>
            </tr>          

            <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
                <img src="images/cam_image.png" >
                Your browser does not support the video tag.
                </video></div>
                <img src="images/cam_image.png"  width="160">
                </div>
                <script type="text/javascript">
                  function difsurvey_start() {
                    document.getElementById('difsurvey_image').style.opacity = "1";
                  }

                  function difsurvey_stop() {
                    document.getElementById('difsurvey_image').style.opacity = "0";
                  }
                  difsurvey_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                
                  <span class="papertitle">In Submission
            </span>
                
                <br>
              <a href="https://chaitanya.one/">Chaitanya Devegupta</a>,
              <a href="https://sumukhaithal6.github.io/">Sumukh Aithal</a>,
              <strong>Shrinivas Ramasubramanian*</strong>,
              Yamada Moyuru,
              Manohar Koul,
              <br>
              <em>CVPR<em>, 2024
                <br>
                <p></p>
                <p>
                  In Submission
                </p>
              </td>
            </tr>              
         

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Patents</h2>
              <p>
                
              </p>
            </td>
            
          </tr>
          
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
              <img src="images/patent.png" >
              Your browser does not support the video tag.
              </video></div>
              <img src="images/patent.png"  width="160">
              </div>
              <script type="text/javascript">
                function difsurvey_start() {
                  document.getElementById('difsurvey_image').style.opacity = "1";
                }

                function difsurvey_stop() {
                  document.getElementById('difsurvey_image').style.opacity = "0";
                }
                difsurvey_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.freepatentsonline.com/y2023/0376846.html">
                <span class="papertitle">INFORMATION PROCESSING APPARATUS AND MACHINE LEARNING METHOD
          </span>
              </a>
              <br>
              <strong>Shrinivas Ramasubramanian</strong>,
              <a href="https://rangwani-harsh.github.io/about/">Harsh Rangwani</a>,
              <a href="https://dblp.dagstuhl.de/pid/155/7291.html">Sho Takemori</a>,
              Kato Takashi,
              <a href="https://scholar.google.com/citations?user=8NWN3xAAAAAJ&hl=ja">Umeda Yuhei</a>,
              <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a>
            <br>
            <em>US Patent No.<em> 20230376846
              <br>
              <p></p>
              <p>
                An information processing apparatus includes one or more memories; and one or more processors coupled to the one or more memories, the one or more processors being configured to decide a gain matrix based on an input metric, perform selection of first training data from a plurality of unlabeled training data, to be used for training a machine learning model, based on the gain matrix, and perform training of the machine learning model based on the first training data, a predicted label that is predicted from the first training data, and a loss function including the gain matrix.
              </p>
            </td>
          </tr>  
          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
              <img src="images/patent.png" >
              Your browser does not support the video tag.
              </video></div>
              <img src="images/patent.png"  width="160">
              </div>
              <script type="text/javascript">
                function difsurvey_start() {
                  document.getElementById('difsurvey_image').style.opacity = "1";
                }

                function difsurvey_stop() {
                  document.getElementById('difsurvey_image').style.opacity = "0";
                }
                difsurvey_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <span class="papertitle">MACHINE LEARNING METHOD AND INFORMATION PROCESSING APPARATUS
          </span>
              
              <br>
              <strong>Shrinivas Ramasubramanian</strong>,
              <a href="https://rangwani-harsh.github.io/about/">Harsh Rangwani</a>,
              <a href="https://dblp.dagstuhl.de/pid/155/7291.html">Sho Takemori</a>,
              <a href="https://scholar.google.com/citations?user=fIzwATkAAAAJ&hl=en">Kunal Samanta</a>,
              <a href="https://scholar.google.com/citations?user=8NWN3xAAAAAJ&hl=ja">Umeda Yuhei</a>,
              <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a>
            <br>
            <em>(Pending) Indian Patent Application No.<em> 202331050473
              <br>
              <p></p>
              <p>
                An information processing apparatus includes one or more memories; and one or more processors coupled to the one or more memories, the one or more processors being configured to decide a gain matrix based on an input metric, perform selection of first training data from a plurality of unlabeled training data, to be used for training a machine learning model, based on the gain matrix, and perform training of the machine learning model based on the first training data, a predicted label that is predicted from the first training data, and a loss function including the gain matrix.
              </p>
            </td>
          </tr>  

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <h2>Academic Service</h2>
            <p>
              1. Served as reviewer for NeruIPS'23, AAAI'24, ICML'23 and ICLR'24 <br>
              2. Served as Teaching Assistant for <a href="https://val.cds.iisc.ac.in/DLCV/">DS 265 Deep Learning for Computer Vision</a> fall 2022 offering.
            </p>
          </td>
        </tr>
      </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
        
          
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Notable projects</h2>
              <p>
                
              </p>
            </td>
          </tr>
        </tbody></table>
         

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
        
          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
            <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
            <img src="images/SID.png" >
            Your browser does not support the video tag.
            </video></div>
            <img src="images/SID.png"  width="180">
            </div>
            <script type="text/javascript">
              function difsurvey_start() {
                document.getElementById('difsurvey_image').style.opacity = "1";
              }
        
              function difsurvey_stop() {
                document.getElementById('difsurvey_image').style.opacity = "0";
              }
              difsurvey_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/stablegradients/SeeInTheDark">
              <span class="papertitle"> See in the dark: Adversarial training for image exposure correction
        </span>
            </a>
            <br>
          <strong>Shrinivas Ramasubramanian*</strong>,
          <a href="https://ssrivatsan97.github.io/">Srivatsan Sridhar*</a>,
          <br>
          <em> Course project EE:710, IIT Bombay <em>, 2018
            <br>
            <p></p>
            <p>
              The project aims at achieving an image transformation from a low exposure image taen in a dimly lit environment to that taken by a long exposure camera.the dataset that has been used is the SID. Dataset prepared thanks to C. Chen et. al. For detailed analysis please refer to the project report named report.pdf .
            </p>
          </td>
        </tr> 

        <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
          <td style="padding:20px;width:15%;vertical-align:middle">
            <div class="one">
            <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
            <img src="images/SemSeg.png" >
            Your browser does not support the video tag.
            </video></div>
            <img src="images/SemSeg.png"  width="180">
            </div>
            <script type="text/javascript">
              function difsurvey_start() {
                document.getElementById('difsurvey_image').style.opacity = "1";
              }
        
              function difsurvey_stop() {
                document.getElementById('difsurvey_image').style.opacity = "0";
              }
              difsurvey_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/stablegradients/SemanticSegmentation">
              <span class="papertitle"> Semantic Segmentation for autonomous vehicles
        </span>
            </a>
            <br>
          <strong>Shrinivas Ramasubramanian*</strong>,
          <br>
          <em> Project under SeDriCa: Autonomous Vehicle Developement, IIT Bombay <em>, 2019
            <br>
            <p></p>
            <p>
              This work involves the use of an encoder decoder architecture CNN for semantic segmentation of the image. We took inspiration from  <a href="//arxiv.org/abs/1707.03718">LinkNet</a> for the same and trained our model oon both the mapillary dataset and the Berkley Deep Drive dataset.

            </p>
          </td>
        </tr> 

        <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
            <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
            <img src="images/SSR-arch.png" >
            Your browser does not support the video tag.
            </video></div>
            <img src="images/SSR-arch.png"  width="180">
            </div>
            <script type="text/javascript">
              function difsurvey_start() {
                document.getElementById('difsurvey_image').style.opacity = "1";
              }
        
              function difsurvey_stop() {
                document.getElementById('difsurvey_image').style.opacity = "0";
              }
              difsurvey_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/stablegradients/SuperResolution">
              <span class="papertitle"> Image Super Resolution
        </span>
            </a>
            <br>
          <strong>Shrinivas Ramasubramanian</strong>,
          <br>
          <em> Course project, IIT Bombay <em>, 2018
            <br>
            <p></p>
            <p>
              This project incorporates a supervised super-resolution scheme by having the process of super-resolving the image to a slightly lesser resoltion. This approach allows the model to learn necessary features at each scale of resolution.This work is highly inspired by Yifan Wang et-al who followed a simillar progressive super-resolution approach.
            </p>
          </td>
        </tr> 


      </tbody></table>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
