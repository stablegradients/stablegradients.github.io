<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Shrinivas Ramasubramanian</title>

    <meta name="author" content="Shrinivas Ramasubramanian">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Shrinivas Ramasubramanian
                </p>
                <p>
                  I am an MS student in Robotics at the
                  <a href="https://www.ri.cmu.edu/">Robotics Institute</a>,
                  <a href="https://www.cmu.edu/">Carnegie Mellon University</a>,
                  working with <a href="https://www.cs.cmu.edu/~schneide/">Jeff Schneider</a> on
                  making model-based reinforcement learning more stable and sample-efficient under
                  distribution shift. Previously, I was a research engineer at
                  <a href="https://www.fujitsu.com/in/about/local/corporate/subsidiaries/fri-research-vision.html">Fujitsu Research</a>
                  in Bangalore and a project assistant in the
                  <a href="https://val.cds.iisc.ac.in/">Vision &amp; AI Lab (VAL)</a> at IISc Bengaluru,
                  where I worked with <a href="https://scholar.google.com/citations?user=8NWN3xAAAAAJ&hl=en">Yuhei Umeda</a>,
                  <a href="https://cds.iisc.ac.in/faculty/venky/">R. Venkatesh Babu</a>, and
                  <a href="https://www.comp.nus.edu.sg/~ayao/">Angela Yao</a> on cost-sensitive learning,
                  non-decomposable objectives, and temporal action segmentation. My work on objective-aligned
                  semi-supervised learning and selective mixup fine-tuning has appeared at
                  <a href="https://arxiv.org/abs/2304.14738">NeurIPS 2022</a> and
                  <a href="https://openreview.net/forum?id=rxVBKhyfSo">ICLR 2024 (Spotlight)</a>, and I have
                  recent papers on long-tailed temporal action segmentation at
                  <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04389.pdf">ECCV 2024</a> and
                  <a href="https://arxiv.org/pdf/2503.18358">BMVC 2024</a>, as well as work on flatter-minima
                  training for world models accepted to
                  <a href="https://openreview.net/pdf?id=vcB1OwtWUZ">NeurIPS 2025</a>. I completed my
                  undergraduate degree in Electrical Engineering at
                  <a href="https://www.iitb.ac.in/">IIT Bombay</a>.
                </p>
                
                <p style="text-align:center">
                  <a href="mailto:shrinivas.ramasubramanian@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Resume_Split.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=igm1_28AAAAJ">Scholar</a> &nbsp;/&nbsp;
				        <a href="https://github.com/stablegradients">Github</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/shrinivas-ramasubramanian-2953721b9/">Linkedin</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Shrinivas.JPG" target="_blank"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Shrinivas.JPG" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My primary area of focus is fairness, constrained optimization problems in deep neural networks. My secondary areas of research are classification on class-imbalanced data, semi-supervised and representation learning. Currently I am hoping to venture out into a couple of areas like large language models, video generation and data centric machine learning for unsupervised and semi-supervised learning.
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="flatten_stop()" onmouseover="flatten_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                <div class="two" id='flatten_image'>
                  <a target="_blank" href="./images/arxiv.png">
                    <img src="images/arxiv.png" width="100%" alt="NeurIPS 2025 Image">
                  </a>
                </div>
                <a target="_blank" href="./images/arxiv.png">
                  <img src="images/arxiv.png" width="100%" alt="NeurIPS 2025 Image">
                </a>
                </div>
                <script type="text/javascript">
                  function flatten_start() {
                    document.getElementById('flatten_image').style.opacity = "1";
                  }

                  function flatten_stop() {
                    document.getElementById('flatten_image').style.opacity = "0";
                  }
                  flatten_stop();
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/pdf?id=vcB1OwtWUZ">
                      <span class="papertitle">Improving Model-Based Reinforcement Learning by Converging to Flatter Minima</span>
                  </a>
                  <br>
                  <strong>Shrinivas Ramasubramanian</strong>, Ben Freed, Alexandre Capone, Jeff Schneider
                  <br>
                  <em>NeurIPS</em>, 2025 
                  <br>
                  <p></p>
                  <p>
                    Model-based reinforcement learning pipelines often collapse once the policy leaves the world model’s nominal operating region. We introduce a flat-minima regularizer that pairs sharpness-aware updates with spectral control on the dynamics model, yielding stable rollouts and markedly higher sample efficiency under distribution shift across offline and online benchmarks.
                  </p>
              </td>
          </tr>

          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
              <td style="padding:20px;width:5%;vertical-align:middle">
                  <div class="one">
                      <div class="two" id="difsurvey_image">
                          <a target="_blank" href="./images/ICLR.png">
                              <img src="images/ICLR.png" width="100%" alt="ICLR Image">
                          </a>
                      </div>
                      <img src="images/ICLR.png" width="100%" alt="ICLR Image">
                  </div>
                  <script type="text/javascript">
                      function difsurvey_start() {
                          document.getElementById('difsurvey_image').style.opacity = "1";
                      }
          
                      function difsurvey_stop() {
                          document.getElementById('difsurvey_image').style.opacity = "0";
                      }
                      difsurvey_stop();
                  </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/forum?id=rxVBKhyfSo">
                      <span class="papertitle">Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Metrics</span>
                  </a>
                  <br>
                  <strong>Shrinivas Ramasubramanian*</strong>,
                  <a href="https://rangwani-harsh.github.io/about/">Harsh Rangwani*</a>,
                  <a href="https://dblp.dagstuhl.de/pid/155/7291.html">Sho Takemori*</a>,
                  <a href="https://scholar.google.com/citations?user=fIzwATkAAAAJ&hl=en">Kunal Samanta</a>,
                  <a href="https://scholar.google.com/citations?user=8NWN3xAAAAAJ&hl=ja">Umeda Yuhei</a>,
                  <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a>,
                  <br>
                  <em>ICLR</em>, 2024 <strong>spotlight presentation</strong>, also presented at ICML workshop differentiable almost everything
                  <br>
                  <p></p>
                  <p>
                      Internet usage growth generates massive data, prompting adoption of supervised/semi-supervised machine learning. Pre-deployment model evaluation, considering worst-case recall and fairness, is crucial. Current techniques lack on non-decomposable objectives; theoretical methods demand building new models for each. Introducing SelMix—a selective mixup-based, cost-effective fine-tuning for pre-trained models. SelMix optimizes specific objectives through feature mixup between class samples. Outperforming existing methods on imbalanced classification benchmarks, SelMix significantly enhances practical, non-decomposable objectives.
                  </p>
              </td>
          </tr>

          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <div class="two" id='difsurvey_image'>
                        <a target="_blank" href="./images/CSST.png">
                            <img src="images/CSST.png" width="100%"  alt="CSST Image">
                        </a>
                    </div>
                    
                </div>
                <script type="text/javascript">
                    function difsurvey_start() {
                        document.getElementById('difsurvey_image').style.opacity = "1";
                    }
        
                    function difsurvey_stop() {
                        document.getElementById('difsurvey_image').style.opacity = "0";
                    }
                    difsurvey_stop();
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2304.14738">
                    <span class="papertitle">Cost-Sensitive Self-Training for Optimizing Non-Decomposable Metrics</span>
                </a>
                <br>
                <a href="https://rangwani-harsh.github.io/about/">Harsh Rangwani*</a>,
                <strong>Shrinivas Ramasubramanian*</strong>,
                <a href="https://dblp.dagstuhl.de/pid/155/7291.html">Sho Takemori*</a>,
                Kato Takashi,
                <a href="https://scholar.google.com/citations?user=8NWN3xAAAAAJ&hl=ja">Umeda Yuhei</a>,
                <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a>,
                <br>
                <em>NeurIPS</em>, 2022
                <br>
                <p></p>
                <p>
                    This work introduces the Cost-Sensitive Self-Training (CSST) framework, which extends self-training-based methods to optimize non-decomposable metrics in practical machine learning systems. The CSST framework proves effective in improving non-decomposable metric optimization using unlabeled data, leading to better results in various vision and NLP tasks compared to state-of-the-art methods.
                </p>
            </td>
          </tr>
            
          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='difsurvey_image'>
                <a target="_blank" href="./images/pang-eccv.png">
                  <img src="images/pang-eccv.png" width="100%" alt="ECCV Image">
                </a>
              </div>
              <a target="_blank" href="./images/pang-eccv.png">
                <img src="images/pang-eccv.png" width="100%" alt="ECCV Image">
              </a>
              </div>
              <script type="text/javascript">
                function difsurvey_start() {
                  document.getElementById('difsurvey_image').style.opacity = "1";
                }

                function difsurvey_stop() {
                  document.getElementById('difsurvey_image').style.opacity = "0";
                }
                difsurvey_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Long-Tail Temporal Action Segmentation with Group-wise Temporal Logit Adjustment
          </span>
              
              <br>
            <a href="https://pangzhan27.github.io/">Pang Zhanzong</a>,
            <a href="https://scholar.google.com/citations?user=-juoweoAAAAJ&hl=en">Fadime Sener</a>,
            <strong>Shrinivas Ramasubramanian</strong>,
            <a href="https://www.comp.nus.edu.sg/~ayao/">Angela Yao</a>
            <br>
            <em>ECCV<em>, 2024
              <br>
              <p></p>
              <p>
                Temporal action segmentation assigns labels to each frame in untrimmed videos, often facing a long-tailed action distribution due to varying action frequencies and durations. However, current methods overlook this issue and struggle with recognizing rare actions. Existing long-tail methods, which make class-independent assumptions, also fall short in this context. To address these challenges, we propose a novel framework called Group-wise Temporal Logit Adjustment (G-TLA). G-TLA leverages activity information and action order to improve tail action recognition. Our approach shows significant improvements on five temporal segmentation benchmarks.
              </p>
            </td>
          </tr>      
          
          
          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='difsurvey_image'>
                <a target="_blank" href="./images/BMVC.png">
                  <img src="images/BMVC.png" width="100%"  alt="BMVC Image">
                </a>
              </div>
              <a target="_blank" href="./images/BMVC.png">
                <img src="images/BMVC.png" width="100%"  alt="BMVC Image">
              </a>
              <script type="text/javascript">
                function difsurvey_start() {
                  document.getElementById('difsurvey_image').style.opacity = "1";
                }

                function difsurvey_stop() {
                  document.getElementById('difsurvey_image').style.opacity = "0";
                }
                difsurvey_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Cost-sensitive learning for long-tailed temporal action segmentation
          </span>
              
              <br>
            <a href="https://pangzhan27.github.io/">Pang Zhanzong</a>,
            <a href="https://scholar.google.com/citations?user=-juoweoAAAAJ&hl=en">Fadime Sener</a>,
            <strong>Shrinivas Ramasubramanian</strong>,
            <a href="https://www.comp.nus.edu.sg/~ayao/">Angela Yao</a>
            <br>
            <em>BMVC<em>, 2024
              <br>
              <p></p>
              <p>
                Temporal action segmentation in untrimmed procedural videos aims to densely label frames into action classes. These videos inherently exhibit long-tailed distributions, where actions vary widely in frequency and duration. In temporal action segmentation approaches, we identified a bi-level learning bias. This bias encompasses (1) a class-level bias, stemming from class imbalance favoring head classes, and (2) a transition-level bias arising from variations in transitions, prioritizing commonly observed transitions. As a remedy, we introduce a constrained optimization problem to alleviate both biases. We define learning states for action classes and their associated transitions and integrate them into the optimization process. We propose a novel cost-sensitive loss function formulated as a weighted cross-entropy loss, with weights adaptively adjusted based on the learning state of actions and their transitions. Experiments on three challenging temporal segmentation benchmarks and various frameworks demonstrate the effectiveness of our approach, resulting in significant improvements in both per-class frame-wise and segment-wise performance.
              </p>
            </td>
          </tr>      

          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
              <img src="images/arxiv.png" >
              Your browser does not support the video tag.
              </video></div>
              <img src="images/arxiv.png"  width="100%">
              </div>
              <script type="text/javascript">
                function difsurvey_start() {
                  document.getElementById('difsurvey_image').style.opacity = "1";
                }

                function difsurvey_stop() {
                  document.getElementById('difsurvey_image').style.opacity = "0";
                }
                difsurvey_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <span class="papertitle"><a href="https://arxiv.org/pdf/2406.12944"> Semantic Graph Consistency: Going Beyond Patches for Regularizing Self-Supervised Vision Transformers</a>
          </span>
              
              <br>
            <a href="https://chaitanya.one/">Chaitanya Devegupta</a>,
            <a href="https://sumukhaithal6.github.io/">Sumukh Aithal</a>,
            <strong>Shrinivas Ramasubramanian</strong>,
            Yamada Moyuru,
            Manohar Koul,
            <br>
            <em>CVPR<em>, 2024
              <br>
              <p></p>
              <p>
                Self-supervised learning (SSL) with vision transformers (ViTs) excels in representation learning but often underutilizes ViT patch tokens. We introduce the Semantic Graph Consistency (SGC) module, which enhances ViT-based SSL by treating images as graphs, with patches as nodes. This approach uses Graph Neural Networks for message passing and regularizes SSL by enforcing consistency between graph features across different image views.
              </p>
            </td>
          </tr>              

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Patents</h2>
              <p>
                
              </p>
            </td>
            
          </tr>
          
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
              <img src="images/patent.png" >
              Your browser does not support the video tag.
              </video></div>
              <img src="images/patent.png"  width="160">
              </div>
              <script type="text/javascript">
                function difsurvey_start() {
                  document.getElementById('difsurvey_image').style.opacity = "1";
                }

                function difsurvey_stop() {
                  document.getElementById('difsurvey_image').style.opacity = "0";
                }
                difsurvey_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.freepatentsonline.com/y2023/0376846.html">
                <span class="papertitle">INFORMATION PROCESSING APPARATUS AND MACHINE LEARNING METHOD
          </span>
              </a>
              <br>
              <strong>Shrinivas Ramasubramanian</strong>,
              <a href="https://rangwani-harsh.github.io/about/">Harsh Rangwani</a>,
              <a href="https://dblp.dagstuhl.de/pid/155/7291.html">Sho Takemori</a>,
              Kato Takashi,
              <a href="https://scholar.google.com/citations?user=8NWN3xAAAAAJ&hl=ja">Umeda Yuhei</a>,
              <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a>
            <br>
            <em>US Patent No.<em> 20230376846
              <br>
              <p></p>
              <p>
                
              </p>
            </td>
          </tr>  
          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:5%;vertical-align:middle">
              <div class="one">
              <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
              <img src="images/patent.png" height="100%" >
              Your browser does not support the video tag.
              </video></div>
              <img src="images/patent.png"  width="100%">
              </div>
              <script type="text/javascript">
                function difsurvey_start() {
                  document.getElementById('difsurvey_image').style.opacity = "1";
                }

                function difsurvey_stop() {
                  document.getElementById('difsurvey_image').style.opacity = "0";
                }
                difsurvey_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <span class="papertitle">MACHINE LEARNING METHOD AND INFORMATION PROCESSING APPARATUS
          </span>
              
              <br>
              <strong>Shrinivas Ramasubramanian</strong>,
              <a href="https://rangwani-harsh.github.io/about/">Harsh Rangwani</a>,
              <a href="https://dblp.dagstuhl.de/pid/155/7291.html">Sho Takemori</a>,
              <a href="https://scholar.google.com/citations?user=fIzwATkAAAAJ&hl=en">Kunal Samanta</a>,
              <a href="https://scholar.google.com/citations?user=8NWN3xAAAAAJ&hl=ja">Umeda Yuhei</a>,
              <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a>
            <br>
            <em>(Pending) Indian Patent Application No.<em> 202331050473
              <br>
              <p></p>
              <p>
                
              </p>
            </td>
          </tr>  

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <h2>Academic Service</h2>
            <p>
              1. Served as reviewer for NeruIPS'23, AAAI'24, ICML'23 and ICLR'24 <br>
              2. Served as Teaching Assistant for <a href="https://val.cds.iisc.ac.in/DLCV/">DS 265 Deep Learning for Computer Vision</a> fall 2022 offering.
            </p>
          </td>
        </tr>
      </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
        
          
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Notable projects</h2>
              <p>
                
              </p>
            </td>
          </tr>
        </tbody></table>
         

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
        
          <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <div class="two" id='difsurvey_image'>
                        <a target="_blank" href="./images/SID.png">
                            <img src="images/SID.png" width="100%"  alt="SID Image">
                        </a>
                    </div>
                    
                </div>
                <script type="text/javascript">
                    function difsurvey_start() {
                        document.getElementById('difsurvey_image').style.opacity = "1";
                    }
        
                    function difsurvey_stop() {
                        document.getElementById('difsurvey_image').style.opacity = "0";
                    }
                    difsurvey_stop();
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/stablegradients/SeeInTheDark">
                    <span class="papertitle">See in the dark: Adversarial training for image exposure correction</span>
                </a>
                <br>
                <strong>Shrinivas Ramasubramanian*</strong>,
                <a href="https://ssrivatsan97.github.io/">Srivatsan Sridhar*</a>,
                <br>
                <em>Course project EE:710, IIT Bombay</em>, 2018
                <br>
                <p></p>
                <p>
                    The project aims at achieving an image transformation from a low exposure image taken in a dimly lit environment to that taken by a long exposure camera. The dataset used is the SID dataset prepared thanks to C. Chen et al. For detailed analysis, please refer to the project report named report.pdf.
                </p>
            </td>
        </tr>
        
        <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:15%;vertical-align:middle">
                <div class="one">
                    <div class="two" id='difsurvey_image'>
                        <a target="_blank" href="./images/SemSeg.png">
                            <img src="images/SemSeg.png" width="100%"  alt="SemSeg Image">
                        </a>
                    </div>
                    
                </div>
                <script type="text/javascript">
                    function difsurvey_start() {
                        document.getElementById('difsurvey_image').style.opacity = "1";
                    }
        
                    function difsurvey_stop() {
                        document.getElementById('difsurvey_image').style.opacity = "0";
                    }
                    difsurvey_stop();
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/stablegradients/SemanticSegmentation">
                    <span class="papertitle">Semantic Segmentation for autonomous vehicles</span>
                </a>
                <br>
                <strong>Shrinivas Ramasubramanian*</strong>,
                <br>
                <em>Project under SeDriCa: Autonomous Vehicle Development, IIT Bombay</em>, 2019
                <br>
                <p></p>
                <p>
                    This work involves the use of an encoder-decoder architecture CNN for semantic segmentation of the image. We took inspiration from <a href="//arxiv.org/abs/1707.03718">LinkNet</a> and trained our model on both the Mapillary dataset and the Berkeley Deep Drive dataset.
                </p>
            </td>
        </tr>
        
        <tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <div class="two" id='difsurvey_image'>
                        <a target="_blank" href="./images/SSR-arch.png">
                            <img src="images/SSR-arch.png" width="100%"  alt="SSR-arch Image">
                        </a>
                    </div>
                    
                </div>
                <script type="text/javascript">
                    function difsurvey_start() {
                        document.getElementById('difsurvey_image').style.opacity = "1";
                    }
        
                    function difsurvey_stop() {
                        document.getElementById('difsurvey_image').style.opacity = "0";
                    }
                    difsurvey_stop();
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/stablegradients/SuperResolution">
                    <span class="papertitle">Image Super Resolution</span>
                </a>
                <br>
                <strong>Shrinivas Ramasubramanian</strong>,
                <br>
                <em>Course project, IIT Bombay</em>, 2018
                <br>
                <p></p>
                <p>
                    This project incorporates a supervised super-resolution scheme by having the process of super-resolving the image to a slightly lesser resolution. This approach allows the model to learn necessary features at each scale of resolution. This work is highly inspired by Yifan Wang et al., who followed a similar progressive super-resolution approach.
                </p>
            </td>
        </tr>

      </tbody></table>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
